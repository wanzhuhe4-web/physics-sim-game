import streamlit as st
import google.generativeai as genai
from openai import OpenAI
import re

# --- 1. é¡µé¢é…ç½® ---
st.set_page_config(
    page_title="ç‰©ç†å­¦ç”Ÿå­˜æ¨¡æ‹Ÿï¼šä»å…¥é—¨åˆ°å…¥åœŸ",
    page_icon="âš—ï¸",
    layout="wide"
)

# --- 2. ç³»ç»ŸæŒ‡ä»¤ ---
PHYSICS_SYSTEM_PROMPT = """
ä½ æ˜¯ä¸€æ¬¾åä¸ºã€Šç‰©ç†å­¦ç”Ÿå­˜æ¨¡æ‹Ÿã€‹çš„æ–‡å­— RPG å¼•æ“ã€‚
è¯­è¨€é£æ ¼å¹½é»˜é£è¶£ï¼Œå……æ»¡è®½åˆºæ„å‘³ã€‚

# æ ¸å¿ƒæ•°å€¼ (æ¯è½®æ›´æ–°)
| å±æ€§ | å½“å‰å€¼ | ç‰©ç†å­¦å®šä¹‰ |
| :--- | :--- | :--- |
| **å¤´çš®åå…‰åº¦** | 0% | 0%ä¸ºé»‘ä½“ï¼Œ100%ä¸ºå…¨åå°„é•œé¢ï¼ˆç»ä¸–å¼ºè€…ï¼‰ã€‚ |
| **ç²¾ç¥ç†µ** | Low | è¾¾åˆ°â€œçƒ­å¯‚â€(Max) åˆ™ç–¯æ‰é€€å­¦ã€‚ |
| **å¯¼å¸ˆæ€æ„**| 0% | è¾¾åˆ° 100% è§¦å‘â€œé€å‡ºå¸ˆé—¨â€ã€‚ |
| **å­¦æœ¯åƒåœ¾**| 0ç¯‡ | æ¯•ä¸šç¡¬é€šè´§ã€‚ |

# æ¸¸æˆå¾ªç¯æœºåˆ¶
æ¸¸æˆä»¥ **4 ä¸ªå›åˆ**ä¸ºä¸€ä¸ªå‘¨æœŸï¼š
1. **ç¬¬ 1-3 å›åˆ**ï¼šå‰§æƒ…æ¨è¿›ï¼Œå¿…é¡»ç»™å‡º A/B/C
2. **ç¬¬ 4 å›åˆ**ï¼š
   - è§¦å‘ `[EVENT: QUIZ]`
   - ä¸ç»™å‰§æƒ…é€‰é¡¹
3. **è€ƒæ ¸ç»“ç®—**ï¼š
   - æ”¶åˆ° `[ANSWER_QUIZ]`
   - è¯„åˆ†åç«‹åˆ»å›åˆ°å‰§æƒ…
"""

# --- 3. åˆå§‹åŒ–çŠ¶æ€ ---
if "messages" not in st.session_state:
    st.session_state.messages = []
    st.session_state.game_started = False
    st.session_state.is_over = False
    st.session_state.ending_type = None
    st.session_state.final_report = ""
    st.session_state.round_count = 0
    st.session_state.mode = "NORMAL"
    st.session_state.event_content = ""
    st.session_state.field = ""

# --- 4. API ---
def get_ai_response(prompt, backend, temperature):
    try:
        if backend == "Google AI Studio (Gemini)":
            genai.configure(api_key=st.secrets["GEMINI_API_KEY"])
            model = genai.GenerativeModel(
                model_name="gemini-3-flash-preview",
                system_instruction=PHYSICS_SYSTEM_PROMPT
            )
            if "gemini_chat" not in st.session_state:
                st.session_state.gemini_chat = model.start_chat(history=[])
            return st.session_state.gemini_chat.send_message(
                prompt,
                generation_config={"temperature": temperature}
            ).text
        else:
            client = OpenAI(
                api_key=st.secrets["DEEPSEEK_API_KEY"],
                base_url="https://api.deepseek.com"
            )
            msgs = [{"role": "system", "content": PHYSICS_SYSTEM_PROMPT}]
            msgs += st.session_state.messages
            msgs.append({"role": "user", "content": prompt})
            return client.chat.completions.create(
                model="deepseek-chat",
                messages=msgs,
                temperature=temperature
            ).choices[0].message.content
    except Exception as e:
        return f"ğŸš¨ API Error: {str(e)}"

# --- 5. æ ¸å¿ƒåŠ¨ä½œ ---
def handle_action(action_text, input_type="ACTION", display_text=None):
    prefix = {
        "ACTION": "ã€ä½œæ­»ã€‘",
        "QUIZ_ANSWER": "ã€ç­”è¾©ã€‘",
        "REBUTTAL": "ã€å‘å¾®å›å¤ã€‘"
    }

    user_content = display_text if display_text else f"{prefix.get(input_type,'')} {action_text}"
    st.session_state.messages.append({"role": "user", "content": user_content})

    if input_type == "ACTION":
        st.session_state.round_count += 1

    force_quiz = (
        input_type == "ACTION"
        and not st.session_state.is_over
        and st.session_state.round_count > 0
        and st.session_state.round_count % 4 == 0
    )

    # Prompt æ„å»º
    if input_type == "QUIZ_ANSWER":
        prompt = f"[ANSWER_QUIZ]: {action_text}ã€‚è¯·è¯„åˆ†ï¼Œç„¶åç»§ç»­ä¸»çº¿å‰§æƒ…ï¼Œå¿…é¡»ç»™å‡º A/B/C ä¸‰ä¸ªé€‰é¡¹ã€‚"
        st.session_state.mode = "NORMAL"

    elif input_type == "REBUTTAL":
        prompt = f"[GRADE: REBUTTAL]: {action_text}ã€‚ç»§ç»­å‰§æƒ…ï¼Œç»™å‡º A/B/Cã€‚"
        st.session_state.mode = "NORMAL"

    else:
        if force_quiz:
            field = st.session_state.field or "ç‰©ç†"
            prompt = (
                f"{action_text}ï¼ˆç³»ç»ŸæŒ‡ä»¤ï¼šç¬¬ {st.session_state.round_count} è½®ï¼Œ"
                f"å¼ºåˆ¶è€ƒæ ¸å›åˆã€‚ä¸è¦ç»™å‰§æƒ…é€‰é¡¹ï¼Œç›´æ¥è§¦å‘ [EVENT: QUIZ]ï¼Œ"
                f"å›´ç»• {field} å‡ºä¸€é“å•é¡¹é€‰æ‹©é¢˜ï¼Œç»™ A/B/Cã€‚ï¼‰"
            )
        else:
            prompt = f"{action_text}ï¼ˆè¯·ç»™å‡º A/B/C ä¸‰ä¸ªé€‰é¡¹ï¼‰"

    backend = st.session_state.get("backend_selection", "Google AI Studio (Gemini)")
    temperature = st.session_state.get("temperature_setting", 1.0)

    with st.spinner("ğŸ§  å¯¼å¸ˆæ­£åœ¨æ²‰æ€..."):
        res = get_ai_response(prompt, backend, temperature)

    new_mode = "NORMAL"
    clean_res = res

    if "[GAME_OVER:" in res:
        st.session_state.is_over = True
        st.session_state.final_report = re.sub(r"\[GAME_OVER:.*\]", "", res).strip()
        clean_res = st.session_state.final_report

    elif "[EVENT: QUIZ]" in res:
        new_mode = "QUIZ"
        parts = res.split("[EVENT: QUIZ]")
        clean_res = parts[0].strip()
        st.session_state.event_content = parts[1].strip()
        st.toast("âš ï¸ è€ƒæ ¸å›åˆï¼", icon="ğŸš¨")

    if clean_res:
        st.session_state.messages.append({"role": "assistant", "content": clean_res})

    st.session_state.mode = new_mode

# --- 6. ä¸»ç•Œé¢ ---
st.title("âš—ï¸ ç‰©ç†å­¦ç”Ÿå­˜æ¨¡æ‹Ÿï¼šä»å…¥é—¨åˆ°å…¥åœŸ")

for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

st.divider()

# =========================
# æ ¸å¿ƒäº¤äº’åŒºï¼ˆå…³é”®ä¿®æ”¹ï¼‰
# =========================

# --- QUIZï¼šæ˜¾ç¤º A/B/C æŒ‰é’® ---
if st.session_state.mode == "QUIZ":
    st.warning("ğŸš¨ **è€ƒæ ¸æ—¶åˆ»ï¼šå¯¼å¸ˆçš„æ­»äº¡å‡è§†**")
    st.markdown(st.session_state.event_content)

    cols = st.columns(3)
    if cols[0].button("A", use_container_width=True):
        handle_action("A", "QUIZ_ANSWER")
        st.rerun()
    if cols[1].button("B", use_container_width=True):
        handle_action("B", "QUIZ_ANSWER")
        st.rerun()
    if cols[2].button("C", use_container_width=True):
        handle_action("C", "QUIZ_ANSWER")
        st.rerun()

# --- NORMALï¼šåŸæ ·ä¿ç•™ ---
else:
    st.write("ğŸ”§ **æŠ‰æ‹©æ—¶åˆ»ï¼š**")
    cols = st.columns(3)
    if cols[0].button("A", use_container_width=True):
        handle_action("A", "ACTION")
        st.rerun()
    if cols[1].button("B", use_container_width=True):
        handle_action("B", "ACTION")
        st.rerun()
    if cols[2].button("C", use_container_width=True):
        handle_action("C", "ACTION")
        st.rerun()

    if prompt := st.chat_input("è‡ªå®šä¹‰ä½œæ­»æ“ä½œ..."):
        handle_action(prompt, "ACTION")
        st.rerun()
