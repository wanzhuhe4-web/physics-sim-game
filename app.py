import streamlit as st
import google.generativeai as genai

# --- 1. åŸºç¡€é…ç½® ---
st.set_page_config(page_title="ç‰©ç†å­¦æ¨¡æ‹Ÿå™¨", page_icon="âš›ï¸", layout="wide")

# å®‰å…¨è¯»å– API Key
if "GEMINI_API_KEY" not in st.secrets:
    st.error("è¯·åœ¨ Streamlit Cloud çš„ Secrets ä¸­è®¾ç½® GEMINI_API_KEYã€‚")
    st.stop()

genai.configure(api_key=st.secrets["GEMINI_API_KEY"])

# --- 2. é€šç”¨åŒ–ç³»ç»ŸæŒ‡ä»¤ (System Instruction) ---
# æ ¸å¿ƒé€»è¾‘ï¼šæç‚¼å…¨çƒç‰©ç†å­¦åšå£«å…±åŒçš„â€œå—éš¾â€ç‚¹
PHYSICS_SYSTEM_PROMPT = """
ä½ æ˜¯ä¸€æ¬¾åä¸ºã€Šç‰©ç†ç”Ÿå­˜æ¨¡æ‹Ÿï¼šå­¦æœ¯æ·±æ¸Šã€‹çš„ç¡¬æ ¸æ–‡å­— RPG å¼•æ“ã€‚
ä½ çš„ç›®æ ‡æ˜¯æ¨¡æ‹Ÿç‰©ç†å­¦ç ”ç©¶çš„çœŸå®çŠ¶æ€ï¼Œé€šè¿‡é»‘è‰²å¹½é»˜è®©ç©å®¶äº§ç”Ÿå…±é¸£ã€‚

# æ ¸å¿ƒæ•°å€¼è¿½è¸ª
æ¯è½®å›å¤å¼€å¤´å¿…é¡»æ›´æ–° Markdown è¡¨æ ¼ï¼š
| å±æ€§ | æ•°å€¼ | è¯´æ˜ |
| :--- | :--- | :--- |
| **å¤´å‘/Sanå€¼** | 100 | å½’é›¶è§¦å‘â€œçœ‹ç ´çº¢å°˜/è½¬è¡Œå–çº¢è–¯â€ç»“å±€ã€‚ |
| **æˆæœ (Indices)** | 0 | æ¯•ä¸š/æ™‹å‡ç¡¬æŒ‡æ ‡ï¼Œé€šè¿‡å‘è¡¨è®ºæ–‡æå‡ã€‚ |
| **ç»è´¹/èµ„æº** | 50 | å®éªŒå®¤çš„ç‡ƒæ–™ï¼Œå½’é›¶åˆ™é¡¹ç›®åœæ»ã€‚ |
| **å¯¼å¸ˆ/PI å¥½æ„Ÿåº¦** | 50 | å½±å“èµ„æºåˆ†é…å’Œæ¨èä¿¡ï¼Œè¿‡ä½ä¼šè§¦å‘çº¦è°ˆã€‚ |

# æ¸¸æˆé€»è¾‘è®¾å®š
1. åˆ†æ”¯é€‰æ‹©ï¼š
   - å®éªŒç‰©ç† (Experimental)ï¼šæ¶‰åŠå…‰è·¯ã€çœŸç©ºã€è¶…å¯¼ã€æ ·æœ¬æ±¡æŸ“ã€æ¶²æ°¦æ–­ä¾›ã€‚
   - ç†è®º/è®¡ç®—ç‰©ç† (Theoretical/Comp)ï¼šæ¶‰åŠç®—æ³•å‘æ•£ã€è¶…ç®—æ’é˜Ÿã€æ‰‹æ¨å…¬å¼å‘ç°ç¬¬ä¸€è¡Œç¬¦å·é”™ã€‚
2. é€šç”¨å­¦æœ¯æ¢—ï¼š
   - å®¡ç¨¿äººï¼šé‚£ä¸ªæ°¸è¿œæ— æ³•è¢«å–æ‚¦çš„ Reviewer 2ã€‚
   - arXivï¼šä¸Šä¼ å‰ä¸€åˆ†é’Ÿå‘ç°åŒè¡ŒæŠ¢å‘äº†ç±»ä¼¼çš„æˆæœã€‚
   - æŠ¥è´¦ï¼šé¢å¯¹æ¯«æ— é€»è¾‘çš„è´¢åŠ¡æŠ¥é”€æµç¨‹æ„Ÿåˆ°æ™ºå•†å½’é›¶ã€‚
   - ä¼šè®®ï¼šåœ¨ Poster å±•ç¤ºåŒºå°´å°¬åœ°å¯¹è§†è·¯äººã€‚
3. æŠ€èƒ½æµ‹éªŒï¼šéšæœºè¦æ±‚ç©å®¶å›ç­”åŸºç¡€ç‰©ç†æ¦‚å¿µæˆ–çº æ­£ä¸€æ®µä¼ªä»£ç ã€‚

# è¯­è¨€é£æ ¼
- æå…·è®½åˆºæ„å‘³çš„å†·å¹½é»˜ã€‚
- å¼±åŒ–ä»»ä½•å…·ä½“çš„å¤§å­¦åç§°æˆ–å…·ä½“åœ°ç†ä½ç½®ã€‚
- æä¾›ä¸‰ä¸ªé€‰é¡¹ A/B/Cï¼Œåæœå…·æœ‰æ¦‚ç‡æ€§çš„éšæœºæ³¢åŠ¨ã€‚
"""

# --- 3. æ¨¡å‹åŠ è½½ ---
@st.cache_resource
def load_model():
    return genai.GenerativeModel(
        model_name="gemini-3-flash", # ä¿æŒæœ€æ–°æ¨¡å‹
        system_instruction=PHYSICS_SYSTEM_PROMPT
    )

model = load_model()

# --- 4. çŠ¶æ€ç®¡ç† ---
if "chat" not in st.session_state:
    st.session_state.chat = model.start_chat(history=[])
    st.session_state.game_started = False
    st.session_state.messages = []

# --- 5. UI ç•Œé¢ ---
st.title("ğŸ§¬ ç‰©ç†å­¦ç§‘ç ”ç”Ÿå­˜æ¨¡æ‹Ÿå™¨ (Universal Edition)")
st.markdown("---")

with st.sidebar:
    st.header("ğŸ® æ§åˆ¶ä¸­å¿ƒ")
    if st.button("é‡å¼€å­¦æœ¯äººç”Ÿ", type="primary"):
        st.session_state.clear()
        st.rerun()
    st.divider()
    st.info("**Tips:** è¿™é‡Œæ²¡æœ‰æ­£ç¡®çš„è·¯ï¼Œåªæœ‰å¤´å‘è¾ƒå°‘çš„è·¯ã€‚")

# è§’è‰²é€‰æ‹©
if not st.session_state.game_started:
    col1, col2 = st.columns(2)
    with col1:
        role = st.radio("é€‰æ‹©ä½ çš„ç§‘ç ”è·¯å¾„ï¼š", ["å®éªŒç‰©ç† (Experimental)", "ç†è®º/è®¡ç®—ç‰©ç† (Theorist)"])
    with col2:
        direction = st.text_input("ç ”ç©¶é¢†åŸŸï¼š", value="å‡èšæ€ / é‡å­ä¿¡æ¯ / ç»Ÿè®¡åŠ›å­¦")
    
    if st.button("è¿›å…¥å­¦æœ¯ç‚¼ç‹± (Enter Purgatory)"):
        st.session_state.game_started = True
        intro_prompt = f"æˆ‘æ˜¯{role}æ–¹å‘çš„ç ”ç©¶ç”Ÿï¼Œç ”ç©¶é¢†åŸŸæ˜¯{direction}ã€‚è¯·å¼€å¯æˆ‘çš„ç¬¬ä¸€å…³ï¼šå¼€é¢˜æŠ¥å‘Šã€‚"
        
        with st.spinner("å¯¼å¸ˆæ­£åœ¨å®¡æ‰¹ä½ çš„å¼€é¢˜..."):
            response = st.session_state.chat.send_message(intro_prompt)
            st.session_state.messages.append({"role": "assistant", "content": response.text})
        st.rerun()

# æ ¸å¿ƒå¯¹è¯
else:
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    if prompt := st.chat_input("è¾“å…¥ä½ çš„æŠ‰æ‹© (A/B/C)"):
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)
        
        with st.chat_message("assistant"):
            with st.spinner("å¯¼å¸ˆæ­£åœ¨æ‰“å­—..."):
                response = st.session_state.chat.send_message(prompt)
                st.markdown(response.text)
                st.session_state.messages.append({"role": "assistant", "content": response.text})

                st.session_state.messages.append({"role": "assistant", "content": response.text})


